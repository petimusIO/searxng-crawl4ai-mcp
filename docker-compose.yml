# SearXNG + Crawl4AI MCP - Truly Self-Hosted Search & Scrape Stack

services:

  # SearXNG - Open source metasearch engine (built with embedded config)
  searxng:
    build:
      context: .
      dockerfile: Dockerfile.searxng
    container_name: searxng
    ports:
      - "8081:8080"
    environment:
      - SEARXNG_BASE_URL=http://localhost:8081/
      - SEARXNG_SECRET=${SEARXNG_SECRET:-$(openssl rand -hex 32)}
    # Configuration is baked into the image from ./searxng-settings.yml so
    # you no longer need to mount a host file at /etc/searxng/settings.yml.
    # If you do override via Coolify Persistent Storage, make sure you
    # mount a *file* (not a directory) to avoid startup failures.
    cap_drop:
      - ALL
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    cap_add:
      - CHOWN
    networks:
      - search-net
      - coolify
    restart: unless-stopped
    # Limit restart attempts in orchestrators that respect `deploy` so a
    # misconfiguration doesn't trigger infinite rebuild/restart churn.
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 3
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:8080/ || exit 1
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for caching
  redis:
    image: redis:alpine
    command: redis-server --save 30 1 --loglevel warning
    ports:
      - "6380:6379"
    volumes:
      - redis_data:/data
    networks:
      - search-net
    restart: unless-stopped
    healthcheck:
      test: redis-cli ping
      interval: 10s
      timeout: 3s
      retries: 3

  # Crawl4AI service for web scraping
  crawl4ai:
    build:
      context: .
      dockerfile: Dockerfile.crawl4ai
    container_name: crawl4ai
    ports:
      - "8001:8000"
    environment:
      - PROXY_URL=${PROXY_URL}
      - CRAWL4AI_LOG_LEVEL=INFO
    networks:
      - search-net
      - coolify
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs

  # Our MCP Server (orchestrates SearXNG + Crawl4AI)
  # mcp-server:
  #   build: 
  #     context: .
  #     dockerfile: Dockerfile
  #   ports:
  #     - "3003:3003"
  #   environment:
  #     - SEARXNG_URL=http://searxng:8080
  #     - CRAWL4AI_URL=http://crawl4ai:8000
  #     - PROXY_URL=${PROXY_URL}
  #     - LOG_LEVEL=info
  #     - MCP_HTTP_PORT=3003
  #     - MCP_INTERNAL_TOKEN=${MCP_INTERNAL_TOKEN:-}
  #   depends_on:
  #     searxng:
  #       condition: service_healthy
  #     crawl4ai:
  #       condition: service_started
  #   networks:
  #     - search-net
  #     - coolify   # connect to external Coolify network so MCP can be reached by other services
  #   volumes:
  #     - ./logs:/app/logs
  #   restart: unless-stopped

  # Our MCP Server (orchestrates SearXNG + Crawl4AI)
  # mcp-server:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   ports:
  #     - "3003:3003"
  #   environment:
  #     - SEARXNG_URL=http://searxng:8080
  #     - CRAWL4AI_URL=http://crawl4ai:8000
  #     - PROXY_URL=${PROXY_URL}
  #     - LOG_LEVEL=info
  #     - MCP_HTTP_PORT=3003
  #     - MCP_INTERNAL_TOKEN=${MCP_INTERNAL_TOKEN:-}
  #   depends_on:
  #     searxng:
  #       condition: service_healthy
  #     crawl4ai:
  #       condition: service_started
  #   networks:
  #     - search-net
  #     - coolify
  #   volumes:
  #     - ./logs:/app/logs
  #   restart: unless-stopped

volumes:
  redis_data:

networks:
  search-net:
    driver: bridge
  coolify:
    external: true